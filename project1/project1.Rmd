---
title: "STAT542 - - Project 1"
author: "Xiaoming Ji"
output: pdf_document
---

```{r, eval=FALSE, include=FALSE}
all_data = read.csv("Ames_data.csv")
n = nrow(all_data)
ntest = round(n * 0.3)
test_ids = sample(1:n, ntest)

train_data = all_data[-test_ids,]
test_data = all_data[test_ids,]

write.csv(train_data, "train.csv", row.names = FALSE)
write.csv(test_data, "test.csv", row.names = FALSE)
```


```{r}
all_data = read.csv("Ames_data.csv")
TRAIN_FILE_NAME = 'train.csv'
TEST_FILE_NAME = 'test.csv'
```

```{r}
Project1_test_id =  read.table("Project1_test_id.txt", quote="\"", comment.char="")
#train_data = read.csv(TRAIN_FILE_NAME)
#test_data = read.csv(TEST_FILE_NAME)
```


Handle na value
```{r}
log_RMSE = function (true_value, predicted_value) {
  sqrt(mean((log(predicted_value) - log(true_value))^2))
}

get_RMSE = function (true_value, predicted_value) {
  sqrt(mean((predicted_value - true_value)^2))
}

Winsorizing = function (data, filter_by, fraction=.05)
{
   if(length(fraction) != 1 || fraction < 0 ||
         fraction > 0.5) {
      stop("bad value for 'fraction'")
   }
   lim = quantile(data[,filter_by], probs=c(fraction, 1-fraction))
   
   data[data[,filter_by]< lim[1],filter_by] = lim[1]
   data[data[,filter_by] > lim[2], filter_by] = lim[2]
   
   data
}

Winsorizing2 = function (data, exclude_fields, multiple=3)
{
  if(length(multiple) != 1 || multiple <= 0) {
    stop("bad value for 'multiple'")
  }
  
  for (i in 1:dim(data)[2]){
    if(!is.numeric(data[,i]) || colnames(data)[i] %in% exclude_fields) next;
    
    med = median(data[,i])
    y = data[,i] - med
    sc = mad(y, center=0) * multiple

    # med = mean(data[,i])
    # y = data[,i] - med
    # sc = sd(train_data$Garage_Cars) * multiple
    y[ y > sc ] = sc
    y[ y < -sc ] = -sc
    
    data[,i] = y + med
  }
  
  data
}

#Make numerical na value as year built
handle_missing = function(train_data, test_data){
  train_data$Garage_Yr_Blt[is.na(train_data$Garage_Yr_Blt)] =
    train_data$Year_Built[is.na(train_data$Garage_Yr_Blt)]
  test_data$Garage_Yr_Blt[is.na(test_data$Garage_Yr_Blt)] =
    test_data$Year_Built[is.na(test_data$Garage_Yr_Blt)]
  
  list(train_data = train_data, test_data = test_data)
}
```

Pre-processing
```{r}
Add_Variables = function(train_data, test_data){
  #Add total bath variable
  train_data$TotBathrooms = train_data$Full_Bath + (train_data$Half_Bath * 0.5) +
                            train_data$Bsmt_Full_Bath + (train_data$Bsmt_Half_Bath * 0.5)
  test_data$TotBathrooms = test_data$Full_Bath + (test_data$Half_Bath * 0.5) +
                            test_data$Bsmt_Full_Bath + (test_data$Bsmt_Half_Bath * 0.5)
  
  #Add Remodeled variable
  train_data$Remodeled = ifelse(train_data$Year_Built == train_data$Year_Remod_Add, "No", "Yes")
  train_data$Remodeled = factor(train_data$Remodeled)
  test_data$Remodeled = ifelse(test_data$Year_Built == test_data$Year_Remod_Add, "No", "Yes")
  test_data$Remodeled = factor(test_data$Remodeled)
  
  #Add Age variable
  train_data$Age = train_data$Year_Sold - train_data$Year_Remod_Add
  test_data$Age = test_data$Year_Sold - test_data$Year_Remod_Add
  
  #Add IsNew variable
  train_data$IsNew = ifelse(train_data$Year_Sold == train_data$Year_Built, "Yes", "No")
  train_data$IsNew = factor(train_data$IsNew)
  test_data$IsNew = ifelse(test_data$Year_Sold == test_data$Year_Built, "Yes", "No")
  test_data$IsNew = factor(test_data$IsNew)
  
  #Add Total Square Feet
  train_data$TotalSqFeet = train_data$Gr_Liv_Area + train_data$Total_Bsmt_SF
  test_data$TotalSqFeet = test_data$Gr_Liv_Area + test_data$Total_Bsmt_SF
  
  #Consolidating Porch variables
  train_data$TotalPorchSF =  train_data$Open_Porch_SF + train_data$Enclosed_Porch + 
                            train_data$Three_season_porch + train_data$Screen_Porch
  test_data$TotalPorchSF =  test_data$Open_Porch_SF + test_data$Enclosed_Porch + 
                            test_data$Three_season_porch + test_data$Screen_Porch

  
    
  list(train_data = train_data, test_data = test_data)
}

Remove_Variables = function(train_data, test_data){
  #Remove highly correlated, consolidated variables and dominate categorical variables
  dropVars = c('Year_Remod_Add', 'Garage_Yr_Blt', 'Garage_Area', 'Garage_Cond', 'Total_Bsmt_SF', 
               'TotRms_AbvGrd', 'BsmtFin_SF_1', 
               'Full_Bath', 'Half_Bath', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath',
               'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch',
               'Street','Utilities','Land_Slope','Condition_2', 'Roof_Matl', 
               'Heating','Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF',
               'Pool_Area', 'Misc_Val', 'Longitude', 'Latitude')
  
  train_data = train_data[, !colnames(train_data) %in% dropVars]
  test_data = test_data[, !colnames(test_data) %in% dropVars]

  list(train_data = train_data, test_data = test_data)
}
```


```{r}
  CategoricalLevels = list(
    MS_SubClass = c("One_Story_1946_and_Newer_All_Styles","Two_Story_1946_and_Newer",
                    "One_and_Half_Story_Finished_All_Ages", "One_Story_PUD_1946_and_Newer",
                    "One_Story_1945_and_Older", "Two_Story_PUD_1946_and_Newer",
                    "Two_Story_1945_and_Older","Split_or_Multilevel",
                    "Duplex_All_Styles_and_Ages","Two_Family_conversion_All_Styles_and_Ages", 
                    "Split_Foyer", "Two_and_Half_Story_All_Ages", "One_and_Half_Story_Unfinished_All_Ages",
                    "PUD_Multilevel_Split_Level_Foyer", "Misc"),
    MS_Zoning = c("Residential_Low_Density", "Residential_Medium_Density", 
                  "Floating_Village_Residential","Residential_High_Density",
                  "C_all", "Misc"),
    Street = c("Pave", "Misc"),
    Alley = c("No_Alley_Access", "Gravel", "Paved", "Misc"),
    Lot_Shape = c("Regular", "Slightly_Irregular", "Misc"),
    Land_Contour = c("Lvl","HLS", "Bnk", "Misc"),
    Utilities = c("AllPub", "Misc"),
    Lot_Config = c("Inside","Corner","CulDSac", "Misc"),
    Land_Slope = c("Gtl","Mod", "Misc"),
    Neighborhood = c("North_Ames","College_Creek","Old_Town","Edwards","Somerset",
                     "Northridge_Heights","Gilbert","Sawyer","Northwest_Ames",
                     "Sawyer_West","Mitchell","Brookside","Crawford",
                     "Iowa_DOT_and_Rail_Road", "Timberland", "Northridge","Stone_Brook",
                     "South_and_West_of_Iowa_State_University", "Clear_Creek", "Meadow_Village",
                     "Briardale", "Bloomington_Heights", "Veenker", "Northpark_Villa", "Blueste",
                     "Misc"),
    Condition_1 = c("Norm","Feedr", "Misc"),
    Condition_2 = c("Norm", "Misc"),
    Bldg_Type = c("OneFam","TwnhsE","Duplex","Twnhs", "Misc"),
    House_Style = c("One_Story","Two_Story","One_and_Half_Fin", 
                    "SLvl","Misc"),
    Overall_Qual = c("Very_Poor", "Poor","Fair","Below_Average",
                     "Average","Above_Average","Good", "Very_Good", 
                     "Excellent", "Very_Excellent"),
    Overall_Cond = c("Very_Poor", "Poor","Fair","Below_Average",
                     "Average","Above_Average","Good", "Very_Good", 
                     "Excellent", "Very_Excellent"),
    Roof_Style = c("Gable","Hip", "Misc"),
    Roof_Matl = c("CompShg", "Misc"),
    Exterior_1st = c("VinylSd","MetalSd","HdBoard","Wd Sdng","Plywood","CemntBd", "Misc"),
    Exterior_2nd = c("VinylSd","MetalSd","HdBoard","Wd Sdng","Plywood","CmentBd", "Misc"),
    Mas_Vnr_Type = c("None","BrkFace","Stone", "Misc"),
    Exter_Qual = c("Poor", "Fair","Typical","Good" ,"Excellent"),
    Exter_Cond = c("Poor", "Fair","Typical","Good" ,"Excellent"),
    Foundation = c("PConc","CBlock", "BrkTil", "Misc"),
    Bsmt_Qual = c("No_Basement","Poor","Fair","Typical","Good","Excellent"),
    Bsmt_Cond = c("No_Basement","Poor","Fair","Typical","Good","Excellent"),
    Bsmt_Exposure = c("No_Basement", "No", "Mn","Av", "Gd"),
    BsmtFin_Type_1 = c("No_Basement","Unf", "LwQ", "Rec", "BLQ", "ALQ", "GLQ"),
    BsmtFin_Type_2 = c("No_Basement","Unf", "LwQ", "Rec", "BLQ", "ALQ", "GLQ"),
    Heating = c("GasA", "Misc"),
    Heating_QC = c("Poor", "Fair","Typical","Good" ,"Excellent"),
    Central_Air = c("Y", "Misc"),
    Electrical = c("SBrkr","FuseA", "Misc"),
    Kitchen_Qual = c("Poor", "Fair","Typical","Good" ,"Excellent"),
    Functional = c("Sal", "Sev", "Maj2", "Maj1", "Mod", "Min2", "Min1", "Typ"),
    Fireplace_Qu = c("No_Fireplace", "Poor", "Fair","Typical","Good","Excellent"),
    Garage_Type = c("Attchd","Detchd", "BuiltIn", "No_Garage", "Misc"),
    Garage_Finish = c("No_Garage", "Unf", "RFn", "Fin"),
    Garage_Qual = c("No_Garage", "Poor", "Fair","Typical","Good","Excellent"),
    Garage_Cond = c("No_Garage", "Poor", "Fair","Typical","Good","Excellent"),
    Paved_Drive = c("Dirt_Gravel","Partial_Pavement", "Paved"),
    Pool_QC = c("No_Pool", "Fair", "Typical", "Good", "Excellent"),
    Fence = c("No_Fence", "Minimum_Wood_Wire", "Good_Wood", "Minimum_Privacy", "Good_Privacy"),
    Misc_Feature = c("None", "Misc"),
    Sale_Type = c("WD ", "New", "Misc"),
    Sale_Condition = c("Normal", "Partial", "Abnorml", "Misc"),
    
    Remodeled = c("Misc"),
    IsNew = c("Misc")
  )

process_categorical = function(train_data, test_data){
  for (name in names(CategoricalLevels)) {
    if(!name %in% colnames(train_data)) next;
    n = length(CategoricalLevels[[name]])
    if(CategoricalLevels[[name]][n] != "Misc") {
      train_data[,name] = ordered(train_data[,name], levels = CategoricalLevels[[name]])
      test_data[,name] = ordered(test_data[,name], levels = CategoricalLevels[[name]])
      if(sum(!test_data[,name] %in% unique(train_data[,name])) > 0) {
        cat("Undefined test categorical value:", name, "\n")
      }
    } else {
      test_data[,name] = factor(test_data[,name], levels = levels(train_data[,name]))
      max_level = names(sort(table(train_data[,name]), decreasing = TRUE))[1]
      
      if(sum(is.na(test_data[,name])) > 0) cat(name, "\tna\t", sum(is.na(test_data[,name])))
      
      test_data[,name][is.na(test_data[,name])] = max_level
    }
  }
  
  list(train_data = train_data, test_data = test_data)
}

```

Pre-processing
```{r}
cate_to_numeric = function(train_data, test_data){
  train_data$Overall_Qual = as.numeric(train_data$Overall_Qual)
  train_data$Overall_Cond = as.numeric(train_data$Overall_Cond)
  
  test_data$Overall_Qual = as.numeric(test_data$Overall_Qual)
  test_data$Overall_Cond = as.numeric(test_data$Overall_Cond)
  
  list(train_data = train_data, test_data = test_data)
}

```

Process numeric data
```{r}
library(psych)

process_numeric = function(train_data, test_data) {
  #Make Year_Sold and Mo_Sold as factor
  train_data$Year_Sold = factor(train_data$Year_Sold)
  train_data$Mo_Sold = factor(train_data$Mo_Sold)
  test_data$Year_Sold = factor(test_data$Year_Sold, levels=levels(train_data$Year_Sold))
  test_data$Mo_Sold = factor(test_data$Mo_Sold, levels=levels(train_data$Mo_Sold))
  
  #Replace na with most frequent value
  max_level = names(sort(table(train_data$Year_Sold), decreasing = TRUE))[1]
  test_data$Year_Sold[is.na(test_data$Year_Sold)] = max_level
  max_level = names(sort(table(train_data$Mo_Sold), decreasing = TRUE))[1]
  test_data$Mo_Sold[is.na(test_data$Mo_Sold)] = max_level

  for (i in 2:dim(train_data)[2]){
    if(colnames(train_data)[i] %in% c("Sale_Price",names(CategoricalLevels))) next;
  
    if (is.numeric(train_data[, i])) {
      if(skew(train_data[, i]) > 0.8) {
        train_data[, i] = log(train_data[, i] + 1)
        test_data[, i] = log(test_data[, i] + 1)
        #print(colnames(train_data)[i])
      }
    }
  }
  
  list(train_data = train_data, test_data = test_data)
}
```

```{r}
process_output = function (train_data, test_data) {
  train_data$Sale_Price = log(train_data$Sale_Price)
  test_data$Sale_Price = log(test_data$Sale_Price)
  
  list(train_data = train_data, test_data = test_data)
}
```


```{r}
preprocess_data = function(train_data, test_data){
  r = handle_missing(train_data, test_data)
  r = Add_Variables(r$train_data, r$test_data)
  r = Remove_Variables(r$train_data, r$test_data)
  r = process_categorical(r$train_data, r$test_data)
  r = cate_to_numeric(r$train_data, r$test_data)
  r = process_numeric(r$train_data, r$test_data)
  r = process_output(r$train_data, r$test_data)
  # r$train_data = Winsorizing2(r$train_data, c("PIC", "Overall_Qual","Overall_Cond",
  #                                             "Mas_Vnr_Area","BsmtFin_SF_2", "Second_Flr_SF",
  #                                             "Bedroom_AbvGr", "Kitchen_AbvGr", "Garage_Cars",
  #                                             "Wood_Deck_SF"))
  
  list(train_data = r$train_data, test_data = r$test_data)
}

```


Build random forest model
```{r}
library(randomForest)
library(gbm)
library(glmnet)

set.seed(6682)

rf_predict = function(train_data, test_data) {
  x_train = train_data[, !colnames(train_data) %in% c("Sale_Price", "PID")]
  
  rfModel = randomForest(x_train, train_data$Sale_Price,importance = T, ntree=400); 
  
  predict(rfModel, test_data)
}

gbm_predict = function(train_data, test_data) {
  gbmModel = gbm(Sale_Price ~ ., data = train_data, distribution = "gaussian", n.trees = 5000,
               shrinkage = 0.01, interaction.depth = 6, bag.fraction = 0.5, cv.folds = 5, verbose = FALSE)
  
  opt.size = gbm.perf(gbmModel)
  print(opt.size)
  predict(gbmModel, test_data, n.trees = opt.size)
}

lasso_predict = function(train_data, test_data) {
  X_train = train_data[, colnames(train_data) != 'Sale_Price']
  X_train = model.matrix(~. -PID, X_train)
  
  Y_train = train_data$Sale_Price
  
  cv.out = cv.glmnet(X_train, Y_train, alpha = 1)
  
  X_test = test_data[, colnames(test_data) != 'Sale_Price']
  X_test = model.matrix(~. -PID, X_test)
  
  predict(cv.out, s = cv.out$lambda.min, newx = X_test)
}

regression_functions = c(rf_predict, gbm_predict, lasso_predict)
rmse = matrix(0, 10, length(regression_functions))

#for (i in c(3,6,9)){
for (i in 1:10){
  test_pid = Project1_test_id[,i]

  train_data = all_data[!all_data$PID %in% test_pid,]
  test_data = all_data[all_data$PID %in% test_pid,]

  r = preprocess_data(train_data, test_data)
  
  if(sum(is.na(r$train_data)) > 0 || sum(is.na(r$test_data)) > 0) {
    print("NA value found!")
  }
  
  for (f in 1:length(regression_functions)){
    yhat_test = regression_functions[[f]](r$train_data, r$test_data)
    rmse[i, f] = get_RMSE(yhat_test, r$test_data$Sale_Price)
    cat(rmse[i, f], "\t")
  }
  cat("\n")
}
print(rmse)
cat("\n Avg", colMeans(rmse), "\n" )
```


```{r}
library(gbm)

gbm_rmse = rep(0, 10)

for (i in 1:length(gbm_rmse)){
  test_pid = Project1_test_id[,i]

  train_data = all_data[!all_data$PID %in% test_pid,]
  test_data = all_data[all_data$PID %in% test_pid,]

  r = preprocess_data(train_data, test_data)
  
  gbmModel = gbm(Sale_Price ~ ., data = r$train_data, distribution = "gaussian", n.trees = 5000,
               shrinkage = 0.01, interaction.depth = 6, bag.fraction = 0.5, cv.folds = 5)
  
  opt.size = gbm.perf(gbmModel)
  y.pred = predict(gbmModel, r$test_data, n.trees = opt.size)
  gbm_rmse[i] = get_RMSE(y.pred, r$test_data$Sale_Price)
  print(gbm_rmse[i])
}

cat("\n Avg", mean(gbm_rmse), "\n" )
```

Lasso with lambda.1se (R_min, R_1se)
```{r}
library(glmnet)

lasso_rmse = rep(0, 10)

for (i in 1:length(lasso_rmse)){
  test_pid = Project1_test_id[,i]

  train_data = all_data[!all_data$PID %in% test_pid,]
  test_data = all_data[all_data$PID %in% test_pid,]
  r = preprocess_data(train_data, test_data)
  
  X_train = r$train_data[, colnames(r$train_data) != 'Sale_Price']
  X_train = model.matrix(~. -PID, X_train)
  
  Y_train = r$train_data$Sale_Price
  
  cv.out = cv.glmnet(X_train, Y_train, alpha = 1)
  
  X_test = r$test_data[, colnames(r$test_data) != 'Sale_Price']
  X_test = model.matrix(~. -PID, X_test)
  
  Ytest_pred = predict(cv.out, s = cv.out$lambda.min, newx = X_test)
  
  lasso_rmse[i] = get_RMSE(Ytest_pred, r$test_data$Sale_Price)
  print(lasso_rmse[i])
}

cat("\n Avg", mean(lasso_rmse), "\n" )
```



```{r}
one_step_lasso = function(r, x, lam){
  length(r)
  length(x)
  xx = sum(x^2)
  xr = sum(r*x)
  b = (abs(xr) -lam/2)/xx
  b = sign(xr)*ifelse(b>0, b, 0)
  return(b)
}

mylasso_fit = function(X, y, lam, n.iter = 500)
{
  # X: n-by-p design matrix without the intercept
  # y: n-by-1 response vector
  # lam: lambda value
  # n.iter: number of iterations
  p = dim(X)[2]
  
  # Center and scale X and y.
  X = scale(X)
  y = scale(y)
  x_center = attr(X, "scaled:center")
  x_scale = attr(X, "scaled:scale")
  y_center = attr(y, "scaled:center")
  y_scale = attr(y, "scaled:scale")    

  # Initial values for residual and coefficient vector b
  b = rep(0, p)
  r = y
  
  rss_saved = 0
  rss_changed = 1000
  
  for(step in 1:n.iter){
    if (rss_changed < 1e-08) break;
    for(j in 1:p){
      # 1) Update the residual vector to be the one
      # in blue on p37 of [lec_W3_VariableSelection.pdf]. 
      # r <-- current residual + X[, j] * b[j]
      r = r + X[,j] * b[j]

      # 2) Apply one_step_lasso to update beta_j
      # b[j] = one_step_lasso(r, X[, j], lam)
      b[j] = one_step_lasso(r, X[, j], lam)
      
      # 3) Update the current residual vector
      # r <-- r - X[, j] * b[j]
      r = r - X[, j] * b[j]
    }
    rss = sum(r^2)
    #print(rss)
    rss_changed = abs(rss_saved - rss)
    rss_saved = rss
    #print(rss_changed)
    #print(step)
  }

  # Scale back b and add intercept b0
  # For b0, check p13 of [lec_W3_VariableSelection.pdf]. 
  b = b / x_scale
  b0 = y_center - sum(b * x_center)
  
  return(c(b0, b))
}

mylasso_predict = function(X, beta) {
  beta[1] + as.matrix(X) %*% beta[-1]
}
```

```{r}
X_train = train_data[, !colnames(train_data) %in% c('PID','Sale_Price')]
X_train = model.matrix(~., X_train)[,-1]

Y_train = train_data$Sale_Price

X_test = test_data[, !colnames(test_data) %in% c('PID','Sale_Price')]
X_test = model.matrix(~., X_test)[,-1]
Y_test = test_data$Sale_Price

beta = mylasso_fit(X_train, Y_train, 1)

Ytest_pred = mylasso_predict(X_test, beta)
get_RMSE(Ytest_pred, test_data$Sale_Price)
```

