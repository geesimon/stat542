---
title: "CS598 - Project 3"
author: "Xiaoming Ji"
output: pdf_document
---
# Computer System

## Hardware
- Dell Precision Tower 5810
- CPU: Intel Xeon E5-1607 @ 3.10GHz
- Memory: 32GB
- GPU: Nvidia GeForce GTX 1080 (2 cards)

## Software
- OS: Windows 10 Professional 64bit
- R: 3.5.1
- R Packages:
    - text2vec
    - 
    - catboost_0.11.1
    - xgboost_0.71.2
    - randomForest_4.6-14
    - glmnet_2.0-16
    - kernlab_0.9-26

```{r, message=FALSE, warning=FALSE, include=FALSE}
mypackages = c("knitr", "kableExtra")   # required packages
tmp = setdiff(mypackages, rownames(installed.packages()))  # packages need to be installed
if (length(tmp) > 0) install.packages(tmp)
lapply(mypackages, require, character.only = TRUE)
```


```{r, eval=FALSE, include=FALSE}
  all = read.table("data.tsv",stringsAsFactors = F,header = T)
  all$new_id = as.integer(all$new_id)
  all$sentiment = as.integer(all$sentiment)
  all$review = gsub('<.*?>', ' ', all$review)
  splits = splits = read.table("splits.csv", header = T)
```
```{r}
  s = 3
  
  train = all[-which(all$new_id%in%splits[,s]),]
  test = all[which(all$new_id%in%splits[,s]),]
```

```{r}
stop_words = c("i", "me", "my", "myself", "we", "our", "ours", "ourselves", "you", "your", "yours")

prep_fun = tolower
tok_fun = word_tokenizer

t1 = Sys.time()
it_train = itoken(train$review, 
             preprocessor = prep_fun, 
             tokenizer = tok_fun, 
             ids = train$id, 
             progressbar = FALSE)
vocab = create_vocabulary(it_train, stopwords = stop_words, ngram = c(1L, 2L))

# Note that most text2vec functions are pipe friendly!
it_test = itoken(test$review, 
             preprocessor = prep_fun, 
             tokenizer = tok_fun, 
             ids = train$id, 
             progressbar = FALSE)

pruned_vocab = prune_vocabulary(vocab, 
                                 term_count_min = 10, 
                                 doc_proportion_max = 0.5,
                                 doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
# create dtm_train with new pruned vocabulary vectorizer

dtm_train  = create_dtm(it_train, vectorizer)
#dtm_train_l1_norm = normalize(dtm_train, "l1")

# define tfidf model
tfidf = TfIdf$new()
# fit model to train data and transform train data with fitted model
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
# tfidf modified by fit_transform() call!
# apply pre-trained tf-idf transformation to test data
dtm_test = create_dtm(it_test, vectorizer)
dtm_test_tfidf = transform(dtm_test, tfidf)

print(difftime(Sys.time(), t1, units = 'sec'))
```

```{r}
NFOLDS = 5
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train[['sentiment']], 
                              family = 'binomial', 
                              # L1 penalty
                              alpha = 1,
                              # interested in the area under ROC curve
                              type.measure = "auc",
                              # 5-fold cross-validation
                              nfolds = NFOLDS,
                              # high value is less accurate, but has faster training
                              thresh = 1e-3,
                              # again lower number of iterations for faster training
                              maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
```

```{r}
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$sentiment, preds)
```

## Preprocessing and Feature Engineering

Several approaches are taken to pre-process the data.

- Response label: merge *Charged Off* to *Default* and convert the label value to 0 or 1.
- Build new predictors to help training/prediction: 
    - `earliest_cr_line_mon`: derived from *earliest_cr_line* that indicates how many months has elapsed till *2019-1-1* when the borrower's earliest reported credit line was opened.
    - `fico_score`: consolidate *fico_range_high* and *fico_range_low* using formula: *(fico_range_high + fico_range_low) / 2*.
- Level grouping: 
    - `zip_code`: it has more than 900 levels, I group these values to 10 new levels to reduce memory usage and improve performance.
- Remove predictors: remove less useful and redundant predictors.
    - `emp_title` (too many levels), `title` (redundant with *purpose*), `grade` (redundant with *sub_grade*) ,`earliest_cr_line`, `fico_range_high`, `fico_range_low`.

## Models

For testing purpose, I build 7 models,

- Dumb model: this is the simplest model that predict 0.2 for every sample.
- Logistic Regression
- Boosting (XGBoost, CatBoost)
- RandomForest
- Lasso
- liner SVM

Suprisingly, Dumb model can achieve `0.504` logloss score. kernlab *ksvm()* fails to build the model (hang forever).  lasso and random forest don't give me significant improvement than logistic regression and they take much longer time to build. Thus, I will pick `dumb`, `Logistic Regression` and `Boosting` as my final models. 

**Note**: My testing shows CatBoost performs at least 10x faster than XGBoost (with GPU, CatBoost can do even better). In case catboost library is not installed, xgboost will be used.

## Evaluation

I tested all 3 test datasets against these models with the parameters,

- Dumb: None.
- Logistic Regression: liner combination of all available predictors.
- Boosting: One-hot encoding on train/test data then train with the following parameters,
    - CatBoost: loss_function = "Logloss", learning_rate = 0.09, iterations = 1200
    - XGBoost: objective = "binary:logistic", eval_metric = "logloss", eta = 0.09, nrounds = 1200

The LogLoss scores are,

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
load("EVAL.OBJ")

test.results = rbind(eval.obj$loss, Average=colMeans(eval.obj$loss))
kable(test.results) %>%
  kable_styling(latex_options = "striped")
```

```{r eval=FALSE, eval=FALSE, warning=FALSE, include=FALSE}
#########################################################################
# Test code begins

start.time = Sys.time()

LOGLOSS = matrix(0, 3, 3)
rownames(LOGLOSS) = c("Test1", "Test2", "Test3")
TEST_NUM = 0

for (i in 1:3){
  TEST_NUM = i
  TRAIN_FILE_NAME = paste("train",i, ".csv", sep = "")
  TEST_FILE_NAME = paste("test",i, ".csv", sep = "")
  LABEL_FILE_NAME = paste("label",i, ".csv", sep = "")
  source('mymain.R')
}
end.time = Sys.time()
run.time = as.numeric(difftime(end.time, start.time, units = 'secs'))

print(LOGLOSS)
cat("\nComputation time:", ceiling(run.time), "Seconds")

eval.obj = list(loss=LOGLOSS, compute.time=run.time)
save(eval.obj, file="EVAL.OBJ")
```

Computation time: `r ceiling(eval.obj$compute.time)` seconds